{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e70c6a-9317-478a-b63f-bdc8523da485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考文档 https://www.langchain.asia/get_started/quickstart\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "DEEPSEEK_APIKEY = os.environ.get('DEEPSEEK_APIKEY')\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    api_key=DEEPSEEK_APIKEY  # 替换为实际API密钥\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54a1fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangSmith 是 LangChain 官方推出的一个强大的调试、监控和分析平台，专门用于优化基于 LangChain 构建的应用程序。它在 LangChain 生态中扮演着至关重要的角色，主要体现在以下几个方面：\\n\\n---\\n\\n### **1. 调试与开发辅助**\\n   - **可视化工作流**：实时展示 LangChain 应用的执行流程（如 Chain、Agent 的调用步骤），帮助开发者直观理解每个组件的输入、输出和中间状态。\\n   - **错误追踪**：快速定位失败原因（如 API 调用异常、解析错误等），并提供详细的堆栈信息和上下文。\\n   - **Prompt 迭代**：记录每次 LLM 调用的请求和响应，方便开发者优化提示词（Prompt）设计。\\n\\n---\\n\\n### **2. 性能监控与分析**\\n   - **延迟与成本统计**：跟踪每个步骤的耗时（如 LLM 调用、工具执行）和 token 消耗，帮助优化效率并控制成本。\\n   - **质量评估**：通过人工标注或自动指标（如输出一致性、正确性）评估模型表现，支持 A/B 测试不同 Prompt 或模型版本。\\n\\n---\\n\\n### **3. 生产环境支持**\\n   - **日志持久化**：存储所有运行记录，便于事后审计或复现问题。\\n   - **告警机制**：设置阈值（如错误率、延迟），触发异常通知。\\n   - **数据导出**：支持将日志导出为 CSV 或其他格式，用于进一步分析。\\n\\n---\\n\\n### **4. 协作与团队共享**\\n   - **项目共享**：团队可共同查看和标注运行记录，加速问题排查和模型优化。\\n   - **版本对比**：比较不同部署版本的行为差异（如切换 LLM 供应商后的效果）。\\n\\n---\\n\\n### **5. 与 LangChain 的无缝集成**\\n   - **简单接入**：通过环境变量或几行代码即可将 LangChain 应用连接到 LangSmith。\\n   - **全面覆盖**：支持 LangChain 的核心组件（Chains、Agents、Tools、Retrievers 等）。\\n\\n---\\n\\n### **典型使用场景**\\n1. **开发阶段**：快速调试 Agent 的复杂逻辑，验证工具调用的正确性。\\n2. **部署阶段**：监控生产环境的 API 调用稳定性，识别性能瓶颈。\\n3. **优化阶段**：分析不同 Prompt 或模型（如 GPT-4 vs. Claude）的效果差异。\\n\\n---\\n\\n### **总结**\\nLangSmith 是 LangChain 的“官方增强工具”，通过提供端到端的可观测性，显著提升了开发效率和应用可靠性。尤其适合复杂 Agent 系统或需要长期维护的 LLM 应用。对于个人开发者，它能加速实验；对于企业团队，它是保障生产环境稳定的重要基础设施。\\n\\n> 注意：LangSmith 是商业产品（提供免费试用），但开源版本的 LangChain 仍可独立使用。是否需要 LangSmith 取决于项目复杂度和对运维工具的需求。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 612, 'prompt_tokens': 10, 'total_tokens': 622, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 10}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '6e49cd1e-300e-4d95-99a3-45398f18e6d8', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f48cbf6e-d056-464f-ad7d-88ef6f47965f-0', usage_metadata={'input_tokens': 10, 'output_tokens': 612, 'total_tokens': 622, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"langsmith 在langchain中的作用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da7fbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangSmith 是 LangChain 官方提供的监控、调试和测试平台，它在 LangChain 生态系统中扮演着重要角色。以下是它的主要作用：\\n\\n1. **调试和可视化**：\\n   - 提供调用链的完整可视化跟踪\\n   - 显示每个步骤的输入/输出\\n   - 帮助理解复杂的链式调用过程\\n\\n2. **性能监控**：\\n   - 记录每次调用的延迟和资源使用情况\\n   - 提供聚合性能指标\\n   - 识别性能瓶颈\\n\\n3. **测试和评估**：\\n   - 支持创建测试数据集\\n   - 可以运行批量测试\\n   - 提供自动化的质量评估\\n\\n4. **生产环境支持**：\\n   - 记录生产环境的调用日志\\n   - 支持异常检测\\n   - 提供审计跟踪\\n\\n5. **协作功能**：\\n   - 支持团队共享调用跟踪\\n   - 可以添加注释和标签\\n   - 便于知识共享和问题排查\\n\\n使用示例：\\n```python\\nfrom langsmith import Client\\n\\nclient = Client()\\n# 记录一次运行\\nrun = client.create_run(\\n    project_name=\"my-project\",\\n    inputs={\"question\": \"What is LangChain?\"},\\n    execution_order=1,\\n    # 其他元数据...\\n)\\n```\\n\\nLangSmith 特别适合以下场景：\\n- 开发复杂链式调用时调试问题\\n- 评估不同提示词/模型的效果\\n- 监控生产环境中的LLM应用\\n- 团队协作开发LLM应用\\n\\n它弥补了LLM开发中缺乏可视化工具和调试手段的空白，是LangChain生态中的重要组成部分。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 340, 'prompt_tokens': 20, 'total_tokens': 360, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 20}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '9e9c51d9-b91a-4e01-84af-e7caff267bd9', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--4f110874-6e4a-41b2-8060-ff0f24031a1d-0', usage_metadata={'input_tokens': 20, 'output_tokens': 340, 'total_tokens': 360, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个python程序员，最近在学langchain\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain = prompt | llm \n",
    "chain.invoke({\"input\": \"langsmith 在langchain中的作用\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89e0259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith 是 LangChain 团队开发的官方工具，它在 LangChain 生态系统中扮演着 **开发调试、监控和分析** 的重要角色。以下是它的核心作用：\\n\\n---\\n\\n### 1. **可视化调试 & 链路追踪**\\n   - **记录完整调用链**：自动记录 LangChain 应用执行的每一步（LLM 调用、工具调用、中间结果等），以可视化时间线展示。\\n   - **检查中间状态**：无需手动打印日志，可直接查看每个步骤的输入/输出，快速定位问题（如提示词问题、解析错误等）。\\n   - **对比不同运行结果**：方便测试不同参数或提示词的效果。\\n\\n---\\n\\n### 2. **测试与评估**\\n   - **数据集测试**：上传测试数据集，批量运行链（Chain）或代理（Agent），自动对比预期输出与实际输出。\\n   - **性能指标**：统计延迟、Token 消耗、成本等，帮助优化效率。\\n   - **回归测试**：确保代码修改不会引入意外行为。\\n\\n---\\n\\n### 3. **生产环境监控**\\n   - **实时日志**：监控生产环境中链/代理的运行情况，捕获异常。\\n   - **用户行为分析**：统计高频查询、失败请求等，指导迭代方向。\\n   - **告警集成**：配置异常阈值（如错误率突增）。\\n\\n---\\n\\n### 4. **协作与共享**\\n   - **团队协作**：共享运行记录、测试结果，加速调试过程。\\n   - **知识沉淀**：将调试后的优质链保存为模板，供团队复用。\\n\\n---\\n\\n### 与其他工具的关系\\n- **LangChain**：提供构建链/代理的框架。\\n- **LangServe**：用于部署 LangChain 应用为 API。\\n- **LangSmith**：专精于开发和生产中的可观测性，补全工具链闭环。\\n\\n---\\n\\n### 典型使用场景\\n```python\\nfrom langchain_community.llms import OpenAI\\nfrom langsmith import Client\\n\\n# 正常编写 LangChain 代码\\nllm = OpenAI(temperature=0.9)\\nresponse = llm.invoke(\"写一首关于咖啡的诗\")\\n\\n# LangSmith 自动记录（需设置环境变量）\\nclient = Client()\\nruns = client.list_runs()  # 查看历史运行记录\\n```\\n\\n---\\n\\n### 总结\\nLangSmith 相当于 LangChain 的 **\"开发者控制台\"**，通过提供端到端的可观测性，显著降低开发复杂 LLM 应用的调试难度，尤其适合涉及多步骤、外部工具调用的场景。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    " \n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\": \"langsmith 在langchain中的作用\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75469c0f-ba25-4ce5-a502-b9d3cbfd875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j8/bzv3vrwj1g976kf9kpg89qwm0000gn/T/ipykernel_97201/3204698306.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "/Users/yetongxue/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://zhuanlan.zhihu.com/p/687882003\")\n",
    " \n",
    "docs = loader.load()\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-zh-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'}  # 使用GPU可改为 'cuda'\n",
    ")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    " \n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# 保存索引到本地\n",
    "# vector.save_local(\"faiss_index\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de99d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    " \n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"参考下面的内容回答问题:\n",
    "{context}\n",
    "问题: {input}\"\"\")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    " \n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483a18c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在LangChain生态中，**LangSmith** 是一个关键的工具平台，主要用于**开发监控、调试、测试和持续改进基于LangChain构建的AI应用**。其核心作用可总结为以下方面：\\n\\n---\\n\\n### 1. **全链路追踪与调试**\\n   - **记录LLM调用过程**：自动跟踪LangChain应用的每一步执行（如模型调用、工具使用、链式流程），可视化展示输入、输出、耗时及错误。\\n   - **问题定位**：通过时间线视图快速定位性能瓶颈或逻辑错误（例如提示词设计缺陷、工具调用顺序问题）。\\n\\n---\\n\\n### 2. **测试与版本迭代**\\n   - **数据集测试**：支持导入测试数据集，批量运行链（Chain）或代理（Agent），对比不同提示词或模型版本的效果（如准确率、延迟）。\\n   - **回归测试**：确保代码更新后核心功能不受影响。\\n\\n---\\n\\n### 3. **生产环境监控**\\n   - **实时监控**：跟踪生产环境中AI应用的表现，记录异常（如API失败、高延迟）。\\n   - **数据分析**：统计Token消耗、响应时间等指标，优化成本与性能。\\n\\n---\\n\\n### 4. **协作与知识沉淀**\\n   - **团队共享**：开发者可共享运行记录和测试结果，加速协作。\\n   - **知识复用**：将调试经验转化为测试用例，避免重复问题。\\n\\n---\\n\\n### 与其他组件的关联\\n- **依赖LangChain**：需基于LangChain构建的应用才能使用LangSmith。\\n- **补充功能**：弥补了LangChain本地开发时缺乏可视化工具的短板，尤其适合复杂链或长期维护的项目。\\n\\n---\\n\\n### 典型使用场景\\n- 调试一个RAG流程时，检查检索到的文档是否有效传递给LLM。\\n- 比较GPT-4与Claude模型在相同链中的效果差异。\\n- 监控聊天机器人生产环境中的用户提问分布，发现未处理的边缘案例。\\n\\n通过LangSmith，开发者能显著提升LangChain应用的开发效率和可靠性，降低LLM应用的维护成本。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    " \n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"langsmith 在langchain中的作用\"})\n",
    "response[\"answer\"]\n",
    " \n",
    "# LangSmith提供了几个功能，可以帮助进行测试:..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
