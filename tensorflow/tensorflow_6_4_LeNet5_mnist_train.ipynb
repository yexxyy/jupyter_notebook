{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_importer\n",
    "import tensorflow_6_4_LeNet5_mnist_inference as mnist_inference\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE=50\n",
    "LEARNING_RATE_BASE=0.05\n",
    "LEARNING_RATE_DECAY=0.3\n",
    "REGULARAZTION_RATE=0.0001\n",
    "TRAINING_STEPS=10000\n",
    "MOVING_AVERAGE_DECAY=0.99\n",
    "\n",
    "MODEL_SAVE_PATH='./tmp/LeNet5/'\n",
    "MODEL_NAME='model.ckpt'\n",
    "\n",
    "def train(mnist):\n",
    "    x=tf.placeholder(\n",
    "        tf.float32,\n",
    "        [None,mnist_inference.IMAGE_SIZE,mnist_inference.IMAGE_SIZE,mnist_inference.NUM_CHANNELS],\n",
    "        name='x-input'\n",
    "    )\n",
    "    y_=tf.placeholder(tf.float32,[None,mnist_inference.OUTPUT_NODE],name='y-input')\n",
    "    \n",
    "    regularizer=tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    \n",
    "    #向前传播\n",
    "    y=mnist_inference.inference(x,True,regularizer)\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "    \n",
    "    variable_averages=tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)\n",
    "    variable_averages_op=variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    cross_entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    cross_entropy_mean=tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    loss=cross_entropy_mean+tf.add_n(tf.get_collection('losses'))\n",
    "    learning_rate=tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        mnist.train.num_examples/BATCH_SIZE,\n",
    "        LEARNING_RATE_DECAY\n",
    "    )\n",
    "    train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "    \n",
    "    with tf.control_dependencies([train_step,variable_averages_op]):\n",
    "        train_op=tf.no_op(name='train')\n",
    "        \n",
    "    saver=tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(TRAINING_STEPS):\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "            reshaped_xs=np.reshape(xs,[\n",
    "                BATCH_SIZE,\n",
    "                mnist_inference.IMAGE_SIZE,\n",
    "                mnist_inference.IMAGE_SIZE,\n",
    "                mnist_inference.NUM_CHANNELS\n",
    "            ])\n",
    "            _,loss_value,step=sess.run([train_op,loss,global_step],feed_dict={x:reshaped_xs,y_:ys})\n",
    "            \n",
    "            #每1000轮保存一次模型\n",
    "            if i % 1000 ==0:\n",
    "                print 'After %d training steps,loss=%f' % (step,loss_value)\n",
    "                \n",
    "                #保存模型\n",
    "                saver.save(sess,os.path.join(MODEL_SAVE_PATH,MODEL_NAME),global_step=step)\n",
    "                \n",
    "                \n",
    "def main(argv=None):\n",
    "    mnist=input_data.read_data_sets('./MNIST_data',one_hot=True)\n",
    "    train(mnist)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \"\"\"\n",
    "    ValueError: Variable layer1/weights already exists, disallowed. \n",
    "    Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n",
    "    第一次运行将下行代码注释，以后运行放开\n",
    "    \"\"\"\n",
    "#     tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    tf.app.run()\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After 500 training steps,loss=0.878618,learning_rate=0.028958\n",
    "After 1000 training steps,loss=0.853497,learning_rate=0.016753\n",
    "After 1500 training steps,loss=0.801199,learning_rate=0.009692\n",
    "After 2000 training steps,loss=0.705418,learning_rate=0.005607\n",
    "After 2500 training steps,loss=0.719921,learning_rate=0.003244\n",
    "After 3000 training steps,loss=0.685588,learning_rate=0.001877\n",
    "After 3500 training steps,loss=0.731382,learning_rate=0.001086\n",
    "After 4000 training steps,loss=0.632257,learning_rate=0.000628\n",
    "After 4500 training steps,loss=0.700597,learning_rate=0.000363\n",
    "After 5000 training steps,loss=0.659599,learning_rate=0.000210\n",
    "After 5500 training steps,loss=0.721710,learning_rate=0.000122\n",
    "After 6000 training steps,loss=0.663642,learning_rate=0.000070\n",
    "After 6500 training steps,loss=0.689002,learning_rate=0.000041\n",
    "After 7000 training steps,loss=0.644999,learning_rate=0.000024\n",
    "After 7500 training steps,loss=0.660535,learning_rate=0.000014\n",
    "After 8000 training steps,loss=0.753764,learning_rate=0.000008\n",
    "After 8500 training steps,loss=0.775101,learning_rate=0.000005\n",
    "After 9000 training steps,loss=0.762689,learning_rate=0.000003\n",
    "After 9500 training steps,loss=0.871014,learning_rate=0.000002\n",
    "After 10000 training steps,loss=0.655120,learning_rate=0.000001\n",
    "\n",
    "\n",
    "After 10000 training steps,accuracy=0.982400"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
