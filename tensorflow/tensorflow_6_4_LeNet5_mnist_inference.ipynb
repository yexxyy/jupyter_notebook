{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet模型结构图\n",
    "![](https://img-blog.csdn.net/20161013101925074?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)\n",
    "\n",
    "一个卷积层参数个数计算公式：5 x 5 x 1 x 6 + 6\n",
    "\n",
    "参数解释：\n",
    "* 5*5卷积核大小\n",
    "* 1 卷积核通道数（与被卷积核通道数一致）\n",
    "* 6 欲获得的卷积后图片通道数\n",
    "* 6 bias，与欲获得的卷积后图片通道数一致\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#配置神经网络参数\n",
    "INPUT_NODE=784\n",
    "OUTPUT_NODE=10\n",
    "\n",
    "IMAGE_SIZE=28\n",
    "NUM_CHANNELS=1\n",
    "NUM_LABELS=10\n",
    "\n",
    "#第一层卷积\n",
    "CONV1_DEEP=32\n",
    "CONV1_SIZE=5\n",
    "\n",
    "#第二层\n",
    "CONV2_DEEP=64\n",
    "CONV2_SIZE=5\n",
    "\n",
    "#全连接节点个数\n",
    "FC_SIZE=512\n",
    "\n",
    "\n",
    "#通过tf.get_varialbe 函数获取变量作用：\n",
    "#创建变量、测试时通过保存的模型读取变量、变量加载时将滑动平均变量重命名\n",
    "#此函数也将变量正则化损失加入损失集合\n",
    "\n",
    "# def get_weight_variable(shape,regularizer):\n",
    "#     weights=tf.get_variable(\n",
    "#         'weights',\n",
    "#         shape,\n",
    "#         initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "#     )\n",
    "    \n",
    "#     if regularizer!=None:\n",
    "#         tf.add_to_collection('losses',regularizer(weights))\n",
    "#     return weights\n",
    "    \n",
    "#向前传播\n",
    "def inference(input_tensor,train,regularizer):\n",
    "    #第一层卷积\n",
    "    with tf.variable_scope('layer1-conv1'):\n",
    "        conv1_weights=tf.get_variable(\n",
    "            'weights',\n",
    "            [CONV1_SIZE,CONV1_SIZE,NUM_CHANNELS,CONV1_DEEP],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "        )\n",
    "        conv1_biases=tf.get_variable(\n",
    "            'biases',\n",
    "            [CONV1_DEEP],\n",
    "            initializer=tf.constant_initializer(0.0)\n",
    "        )\n",
    "        \n",
    "        conv1=tf.nn.conv2d(input_tensor,conv1_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu1=tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))\n",
    "        \n",
    "    #第二层池化\n",
    "    with tf.name_scope('layer2-pool1'):\n",
    "        pool1=tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "    #第三层卷积\n",
    "    with tf.variable_scope('layer3-conv2'):\n",
    "        conv2_weights=tf.get_variable(\n",
    "            'weights',\n",
    "            [CONV2_SIZE,CONV2_SIZE,CONV1_DEEP,CONV2_DEEP],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "        )\n",
    "        \n",
    "        conv2_biases=tf.get_variable(\n",
    "            'biases',\n",
    "            [CONV2_DEEP],\n",
    "            initializer=tf.constant_initializer(0.0)\n",
    "        )\n",
    "        conv2=tf.nn.conv2d(pool1,conv2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu2=tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n",
    "        \n",
    "    \n",
    "    #第四层池化\n",
    "    with tf.name_scope('layer4-pool2'):\n",
    "        pool2=tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        \n",
    "    \n",
    "    # 将pool2中的图片展开，注意第一维是batch,pool2_shape[0]为一批次中数据的个数\n",
    "    pool2_shape = pool2.get_shape().as_list()\n",
    "    nodes = pool2_shape[1] * pool2_shape[2] * pool2_shape[3]\n",
    "    reshaped = tf.reshape(pool2, [-1, nodes])\n",
    "    \n",
    "    #第五层（全连接第一层）\n",
    "    with tf.variable_scope('layer5-fc1'):\n",
    "        fc1_weights=tf.get_variable(\n",
    "            'weights',\n",
    "            [nodes,FC_SIZE],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "        )\n",
    "        \n",
    "        #只有全连接的权重需要加入正则化\n",
    "        if regularizer != None:\n",
    "            tf.add_to_collection('losses',regularizer(fc1_weights))\n",
    "        \n",
    "        \n",
    "        fc1_biases=tf.get_variable(\n",
    "            'biases',\n",
    "            [FC_SIZE],\n",
    "            initializer=tf.constant_initializer(0.1)\n",
    "        )\n",
    "        \n",
    "        fc1=tf.nn.relu(tf.matmul(reshaped,fc1_weights)+fc1_biases)\n",
    "        \n",
    "        if train:\n",
    "            fc1=tf.nn.dropout(fc1,0.5)\n",
    "        \n",
    "    \n",
    "    #第六层（全连接第二层）\n",
    "        \n",
    "    with tf.variable_scope('layer6-fc2'):\n",
    "        fc2_weights=tf.get_variable(\n",
    "            'weights',\n",
    "            [FC_SIZE,NUM_LABELS],\n",
    "            initializer=tf.truncated_normal_initializer(stddev=0.1)\n",
    "        )\n",
    "        \n",
    "        #只有全连接的权重需要加入正则化\n",
    "        if regularizer != None:\n",
    "            tf.add_to_collection('losses',regularizer(fc2_weights))\n",
    "        \n",
    "        fc2_biases=tf.get_variable(\n",
    "            'biases',\n",
    "            [NUM_LABELS],\n",
    "            initializer=tf.constant_initializer(0.1)\n",
    "        )\n",
    "        \n",
    "        logit=tf.matmul(fc1,fc2_weights)+fc2_biases\n",
    "        \n",
    "    return logit\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
