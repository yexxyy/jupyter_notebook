{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://playground.tensorflow.org](http://playground.tensorflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.4427042   0.0992484   0.59122431]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1=tf.random_normal(shape=(2,3),stddev=1,seed=1)\n",
    "sess=tf.Session()\n",
    "print sess.run(w1)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign:0' shape=(2, 2) dtype=float32_ref>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1),name='w1')\n",
    "w2=tf.Variable(tf.random_normal([2,2],stddev=1,dtype=tf.float64),name='w2')\n",
    "\n",
    "#数据类型不一致报错\n",
    "#w1.assign(w2)  \n",
    "\n",
    "w3=tf.Variable(tf.random_normal([2,2],stddev=1),name='w3')\n",
    "#维度不一致可以设置validate_shape=False\n",
    "tf.assign(w1,w3,validate_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练轮数：0，loss=0.485872\n",
      "训练轮数：0，loss=0.485872\n",
      "训练轮数：10，loss=0.467057\n",
      "训练轮数：20，loss=0.450460\n",
      "训练轮数：30，loss=0.438850\n",
      "训练轮数：40，loss=0.431126\n",
      "训练轮数：50，loss=0.420976\n",
      "训练轮数：60，loss=0.417871\n",
      "训练轮数：70，loss=0.415630\n",
      "训练轮数：80，loss=0.410993\n",
      "训练轮数：90，loss=0.407710\n",
      "训练轮数：5000，loss=0.398780\n",
      "训练轮数：10000，loss=0.396055\n",
      "训练轮数：15000，loss=0.392307\n",
      "训练轮数：20000，loss=0.390671\n",
      "训练轮数：25000，loss=0.389889\n",
      "训练轮数：30000，loss=0.389444\n",
      "训练轮数：35000，loss=0.389157\n",
      "训练轮数：40000，loss=0.388954\n",
      "训练轮数：45000，loss=0.388803\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=(None,2),name='x-input')\n",
    "y=tf.placeholder(tf.float32,shape=(None,1),name='y-input')\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1))\n",
    "a=tf.matmul(x,w1)\n",
    "\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1))\n",
    "prediction=tf.sigmoid(tf.matmul(a,w2))\n",
    "\n",
    "tmp=tf.subtract(prediction,y)\n",
    "tmp=tf.abs(tmp)\n",
    "loss=tf.reduce_sum(tmp)\n",
    "train_step=tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "rdm=RandomState(1)\n",
    "dataset_size=1000\n",
    "X=rdm.rand(dataset_size,2)\n",
    "Y=[[int(x1+x2<1)] for (x1,x2) in X]\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init=tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    STEPS=50000\n",
    "    for i in range(STEPS):\n",
    "        start=(i*batch_size) % dataset_size\n",
    "        end=min(start+batch_size,dataset_size)\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y:Y[start:end]})\n",
    "        \n",
    "        if i<100 and i%10==0:\n",
    "            tmp_loss=sess.run(loss/dataset_size,feed_dict={x:X,y:Y})\n",
    "            \n",
    "            print '训练轮数：%d，loss=%f' % (i,tmp_loss)\n",
    "        \n",
    "        if i%5000==0:\n",
    "            tmp_loss=sess.run(loss/dataset_size,feed_dict={x:X,y:Y})\n",
    "            print '训练轮数：%d，loss=%f' % (i,tmp_loss)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[4 3 3 4]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "v1=tf.constant([1,2,3,4])\n",
    "v2=tf.constant([4,3,2,1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print tf.greater(v1,v2).eval()\n",
    "    print tf.where(tf.greater(v1,v2),v1,v2).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.01934695]\n",
      " [ 1.04280889]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "#两个输入节点\n",
    "x=tf.placeholder(tf.float32,shape=(None,2),name='x-input')\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name='y-input')\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))\n",
    "y=tf.matmul(x,w1)\n",
    "\n",
    "#定义预测多了和预测少了的成本\n",
    "loss_less=10\n",
    "loss_more=1\n",
    "\n",
    "loss=tf.reduce_sum(tf.where(tf.greater(y,y_),(y-y_)*loss_more,(y_-y)*loss_less))\n",
    "train_step=tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "rdm=RandomState(1)\n",
    "dataset_size=128\n",
    "X=rdm.rand(dataset_size,2)\n",
    "Y=[[x1+ x2+ rdm.rand()/10.0-0.05] for (x1,x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    STEPS=5000\n",
    "    for i in range(STEPS):\n",
    "        start=(i* batch_size)% dataset_size\n",
    "        end=min(start+batch_size,dataset_size)\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        \n",
    "    print sess.run(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5769778464775016"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#指数衰减（decay）的学习率\n",
    "global_step=tf.Variable(0)\n",
    "\n",
    "learn_rate=tf.train.exponential_decay(0.1,global_step,100,0.96,staircase=True)\n",
    "train_step=tf.train.GradientDescentOptimizer(learn_rate).minimize(...loss...,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正则化\n",
    "loss=tf.reduce_mean(tf.square(y_-y)) + tf.contrib.layers.l2_regularizer(lambda_)(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#集合方式正则化\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_weight(shape,lambda_):\n",
    "    \"\"\"\n",
    "    获取一层网络权重，并将这个权重的L2正则化损失加入名称为losses的集合中\n",
    "    \"\"\"\n",
    "    var=tf.Variable(tf.random_normal(shape),dtype=tf.float32)\n",
    "    \n",
    "    tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(lambda_)(var))\n",
    "    \n",
    "    return var\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=(None,2))\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1))\n",
    "\n",
    "batch_size=8\n",
    "layer_dimension=[2,10,10,10,1]\n",
    "n_layers=len(layer_dimension)\n",
    "\n",
    "#cur_layer维护向前传播时最深层的节点，开始的时候就是输入层\n",
    "cur_layer=x\n",
    "\n",
    "\n",
    "for i in range(1,n_layers):\n",
    "    #当前节点个数\n",
    "    in_dimension=layer_dimension[i-1]\n",
    "    out_dimension=layer_dimension[i]\n",
    "    \n",
    "    weight=get_weight([in_dimension,out_dimension],0.001)\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=[out_dimension]))\n",
    "    \n",
    "    cur_layer=tf.nn.relu(tf.matmul(cur_layer,weight)+bias)\n",
    "\n",
    "    \n",
    "mse_loss=tf.reduce_mean(tf.square(y_-cur_layer))\n",
    "\n",
    "tf.add_to_collection('losses',mse_loss)\n",
    "loss=tf.add_n(tf.get_collection('losses'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  [滑动平均模型（ExponentialMovingAverage）](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/train/ExponentialMovingAverage)\n",
    "When training a model, it is often beneficial to maintain moving averages of the trained parameters. Evaluations that use averaged parameters sometimes produce significantly better results than the final trained values.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[5.0, 4.5]\n",
      "[10.0, 4.5549998]\n"
     ]
    }
   ],
   "source": [
    "#滑动平均模型样例\n",
    "import tensorflow as tf\n",
    "\n",
    "#定义一个变量用于计算滑动平均，初始值0\n",
    "v1=tf.Variable(0,dtype=tf.float32)\n",
    "\n",
    "#step模拟网络迭代次数\n",
    "step=tf.Variable(0,trainable=False)\n",
    "\n",
    "ema=tf.train.ExponentialMovingAverage(0.99,step)\n",
    "maintain_averages_op=ema.apply([v1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    print sess.run([v1,ema.average(v1)])\n",
    "    \n",
    "    \n",
    "    sess.run(tf.assign(v1,5))\n",
    "    sess.run(maintain_averages_op)\n",
    "    print sess.run([v1,ema.average(v1)])\n",
    "    \n",
    "    sess.run(tf.assign(v1,10))\n",
    "    sess.run(tf.assign(step,1000))\n",
    "    sess.run(maintain_averages_op)\n",
    "    print sess.run([v1,ema.average(v1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
